{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "#Image smudging using CNN's\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import pprint\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Load a VGG-16 model\n",
    "from keras import backend as K\n",
    "from keras.applications import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Content Cost\n",
    "def content_cost(generated , base):\n",
    "    cost = K.sum(K.square(generated - base))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Style loss\n",
    "#Create a gram matrix out of the given matrix\n",
    "def gram(A):\n",
    "    #Unroll a 4 dimensional tensor into 3-D and change the order from 0,1,2 to 2,0,1\n",
    "    mat1 = K.batch_flatten(K.permute_dimensions(A, (2, 0, 1)))\n",
    "    return K.dot(mat1, K.transpose(mat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_cost(generated , base):\n",
    "    #Calculate style loss\n",
    "    n_H = base.shape[0]\n",
    "    n_W = base.shape[1]\n",
    "    gram_base = gram(base)\n",
    "    gram_generated = gram(generated)\n",
    "    cost = (1/(2*n_H*n_W)**2) * (K.sum(K.square(gram_generated - gram_base)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variance_cost(x):\n",
    "    #Reguralization factor to smoother the graph\n",
    "    a = K.square(x[:, :-1, :-1, :] - x[:, 1:, :-1, :])\n",
    "    b = K.square(x[:, :-1, :-1, :] - x[:, :-1, 1:, :])\n",
    "    return K.sum(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_outputs(base_image, style_image, dims):\n",
    "    content_img = K.variable(preprocess_image(base_image, dims))\n",
    "    style_img = K.variable(preprocess_image(style_image, dims))\n",
    "    output_img = K.placeholder((1, height, width, 3))\n",
    "    return content_img, style_img, output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_transfer(base_image , style_image , output_image_path , content_reg=3e-2 , var_reg=5e-2):\n",
    "    dims = load_img(base_image).size\n",
    "    height = dims[0]\n",
    "    width = dims[1]\n",
    "    content_img, style_img, output_img = initialize_outputs(base_img , style_img, dms)\n",
    "    input_img = K.concatenate([content_img, style_img, output_img], axis=0)\n",
    "    model = vgg16.VGG16(input_tensor=input_img, weights='imagenet', include_top=False)\n",
    "    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "    content_features = outputs_dict['block4_conv2']\n",
    "    base_image_features = content_features[0, :, :, :]  \n",
    "    combination_features = content_features[2, :, :, :] \n",
    "    content_loss = content_reg * content_cost(combination_features , base_image_features)\n",
    "    style_layers=['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "    temp_style_loss = K.variable(0.0) \n",
    "    weight = 1.0 / float(len(style_layers))\n",
    "    for i, layer in enumerate(style_layers):\n",
    "        style_features = outputs_dict[layer]\n",
    "        style_image_features = style_features[1, :, :, :] \n",
    "        output_style_features = style_features[2, :, :, :] \n",
    "        temp_style_loss += style_weights[i] * weight * \\\n",
    "                    style_cost(output_style_features, style_image_features)\n",
    "    style_loss = temp_style_loss\n",
    "    tv_loss = tv_weight * total_variation_cost(output_img)\n",
    "    total_loss = content_loss + style_loss + tv_loss\n",
    "    grads = K.gradients(total_loss, output_img)\n",
    "    outputs = [total_loss] + grads\n",
    "    loss_and_grads = K.function([output_img], outputs)  \n",
    "    def grads(x):\n",
    "        x = x.reshape((1, height, width, 3))\n",
    "        return loss_and_grads([x])[1].flatten().astype('float64')\n",
    "    def loss(x):\n",
    "        x = x.reshape((1, height, width, 3)) \n",
    "        return loss_and_grads([x])[0]\n",
    "    x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n",
    "    for i in range(51):\n",
    "        x, min_val, info = fmin_l_bfgs_b(loss, x.flatten(), fprime=grads, maxfun=20)\n",
    "        if i%10 == 0:\n",
    "            img = deprocess_image(x.copy(), height, width)\n",
    "            fname = output_img_path + '_at_iteration_%d.png' % (i)\n",
    "            imsave(fname, img)\n",
    "            print('\\t\\tImage saved as', fname)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-99dab8dafe0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstyle_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content.jpg'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'style.jpg'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-324da23188fe>\u001b[0m in \u001b[0;36mstyle_transfer\u001b[0;34m(base_image, style_image, output_image_path, content_reg, var_reg)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstyle_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstyle_image\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutput_image_path\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcontent_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvar_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcontent_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_img\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstyle_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_img' is not defined"
     ]
    }
   ],
   "source": [
    "style_transfer('content.jpg' , 'style.jpg' , 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
